{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ce2206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy as sp\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b09bb521",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = os.listdir('C:/Users/darby/Desktop/Nobel_Laureates')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81d7abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = sp.load(\"en_core_web_sm\")\n",
    "text = []\n",
    "\n",
    "for Laureate in entries:\n",
    "    with open('C:/Users/darby/Desktop/Nobel_Laureates/'+Laureate,\"r\",encoding = 'utf8') as f:\n",
    "        text.append(f.read())\n",
    "        \n",
    "nlp_list = [nlp(i) for i in text]\n",
    "sentences_list = [list(i.sents) for i in nlp_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a12eb22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "979"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf19a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "\n",
    "for i in range(0,979):\n",
    "    if len(sentences_list[i])!=0:\n",
    "        text.append(sentences_list[i][0])\n",
    "    else:\n",
    "        text.append(entries[i][:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b92cd517",
   "metadata": {},
   "outputs": [],
   "source": [
    "npws = []\n",
    "for i in range(0,979):\n",
    "    npws.append(entries[i][:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d897b53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '\\\\'\n",
    "def return_dates(j):\n",
    "    global f\n",
    "    dates = []\n",
    "    \n",
    "    for i in nlp(re.findall('\\(.*\\)',str(text[j]))[0]).ents:\n",
    "        if i.label_=='DATE' and f not in i.text:\n",
    "            dates.append(i.text)\n",
    "   \n",
    "    return dates\n",
    "\n",
    "def entity_gen(text):\n",
    "    nlp_1 = nlp(text)\n",
    "    text_list = list(nlp_1.sents)\n",
    "    text_entities = text_list[0].ents\n",
    "    return text_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64ee5c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# count1 = 0\n",
    "# is_born = []\n",
    "# is_dead = []\n",
    "# laureates = []\n",
    "# no = []\n",
    "\n",
    "# for j in range(0,len(entries)):\n",
    "#     if len(re.findall('\\(.*\\)',str(text[j])))!=0:\n",
    "#         if(entries[j][:-4].strip() == str(text[j]).strip()):\n",
    "#             no.append(j)\n",
    "#             is_born.append('Not Mentioned')\n",
    "#             is_dead.append('Not Mentioned')\n",
    "#         else:\n",
    "#             no.append(j)\n",
    "#             for i in return_dates(j):\n",
    "                \n",
    "#                 if(len(return_dates(j))==2):\n",
    "#                     if count%2==0:\n",
    "#                         is_born.append(i)\n",
    "\n",
    "#                     else:\n",
    "#                         is_dead.append(i)\n",
    "#                 elif(len(return_dates(j))==1):\n",
    "#                     is_born.append(i)\n",
    "#                     is_dead.append('Not Yet')\n",
    "#                 else:\n",
    "#                     if count%2==0:\n",
    "#                         is_born.append(i)\n",
    "\n",
    "#                     else:\n",
    "#                         is_dead.append(i)\n",
    "                    \n",
    "#                 count+=1\n",
    "#     elif(len(re.findall('\\(.*\\)',str(text[j])))==0):\n",
    "#         no.append(j)\n",
    "#         is_born.append('NA')\n",
    "#         is_dead.append('NA')\n",
    "#     else:\n",
    "#         no.append(j)\n",
    "#         print(j)\n",
    "#         is_born.append('NA')\n",
    "#         is_dead.append('NA')\n",
    "#     if()\n",
    "    \n",
    "\n",
    "# print(is_born)\n",
    "# print(is_dead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92fb4523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "979\n",
      "979\n",
      "979\n"
     ]
    }
   ],
   "source": [
    "# print(len(list(filter(lambda x: x not in no, range(0,979)))))\n",
    "print(len(entries))\n",
    "print(len(is_born))\n",
    "print(len(is_dead))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafdf79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(re.findall('\\(.*\\)',str(text[22])))==0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cdcd8f",
   "metadata": {},
   "source": [
    "# Serious Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5b0eb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(born 4 August 1948)\n",
      "(August 1948,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# r = text[0].text\n",
    "# print(r)\n",
    "# print(type(r))\n",
    "\n",
    "print(nlp(re.findall('\\(.*\\)',text[6])[0]))\n",
    "print(nlp(re.findall('\\(.*\\)',text[6])[0]).ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[6].ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9f009268",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'return_dates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-d2c0545e3d5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_dates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m                 \u001b[0mis_born\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_dates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mis_dead\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NA'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'return_dates' is not defined"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "is_born = []\n",
    "is_dead = []\n",
    "laureates = []\n",
    "\n",
    "\n",
    "for j in range(0,len(entries)):\n",
    "    \n",
    "    if len(re.findall('\\(.*\\)',str(text[j])))!=0:\n",
    "        if(entries[j][:-4].strip() == str(text[j]).strip()):\n",
    "            \n",
    "            is_born.append('Not Mentioned')\n",
    "            is_dead.append('Not Mentioned')\n",
    "        else:\n",
    "            \n",
    "            if len(return_dates(j))==1:\n",
    "                is_born.append(return_dates(j)[0])\n",
    "                is_dead.append('NA')\n",
    "            elif len(return_dates(j))>1:\n",
    "                is_born.append(return_dates(j)[0])\n",
    "                is_dead.append(return_dates(j)[1])\n",
    "            else:\n",
    "                is_born.append('NA')\n",
    "                is_dead.append('NA')\n",
    "    elif(len(re.findall('\\(.*\\)',str(text[j])))==0):\n",
    "        is_born.append('NA')\n",
    "        is_dead.append('NA')\n",
    "    else:\n",
    "        \n",
    "        \n",
    "        is_born.append('NA')\n",
    "        is_dead.append('NA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db07d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(text[974])\n",
    "print(is_born[974])\n",
    "print(is_dead[974])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cd8209b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laureate</th>\n",
       "      <th>is_born_on</th>\n",
       "      <th>is_dead_on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andrea M. Ghez</td>\n",
       "      <td>June 16, 1965</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ardem Patapoutian</td>\n",
       "      <td>2 October 1967</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charles M. Rice</td>\n",
       "      <td>August 25, 1952</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David MacMillan</td>\n",
       "      <td>16 March 1968</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Didier Queloz</td>\n",
       "      <td>23 February 1966</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>Yves Chauvin</td>\n",
       "      <td>10 October 1930</td>\n",
       "      <td>27 January 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>Zhores Alferov</td>\n",
       "      <td>15 March 1930</td>\n",
       "      <td>1 March 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>Élie Ducommun</td>\n",
       "      <td>19 February 1833</td>\n",
       "      <td>7 December 1906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>Élie Metchnikoff</td>\n",
       "      <td>15 May</td>\n",
       "      <td>15 July 1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>Óscar Arias</td>\n",
       "      <td>13 September 1940</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>979 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Laureate         is_born_on       is_dead_on\n",
       "0        Andrea M. Ghez      June 16, 1965               NA\n",
       "1     Ardem Patapoutian     2 October 1967               NA\n",
       "2       Charles M. Rice    August 25, 1952               NA\n",
       "3       David MacMillan      16 March 1968               NA\n",
       "4         Didier Queloz   23 February 1966               NA\n",
       "..                  ...                ...              ...\n",
       "974        Yves Chauvin    10 October 1930  27 January 2015\n",
       "975      Zhores Alferov      15 March 1930     1 March 2019\n",
       "976       Élie Ducommun   19 February 1833  7 December 1906\n",
       "977    Élie Metchnikoff             15 May     15 July 1916\n",
       "978         Óscar Arias  13 September 1940               NA\n",
       "\n",
       "[979 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_to_dict = {'Laureate':npws, 'is_born_on':is_born, 'is_dead_on':is_dead }\n",
    "    \n",
    "token_dataframe = pd.DataFrame(dates_to_dict)\n",
    "\n",
    "token_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd29c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE (a:Laureate{Name: \"Andrea M. Ghez\"})RETURN a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354860b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laureate = 'John_the_Humble'\n",
    "# print('CREATE (a: \\'Laureate\\' {\\'Name\\':'+Laureate+'}) RETURN a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72ed059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e76747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from googletrans import Translator, constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210f3c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 uninstall googletrans\n",
    "# !pip3 install googletrans==3.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d77988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = Translator\n",
    "# t = r.translate(\"Hola Mundo\", dest=\"ar\")\n",
    "# t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f3f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Laureate = 'John'\n",
    "print('CREATE (a:Laureate{Name:'+\"\\\"\"+Laureate+\"\\\"\"+'})RETURN a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b6a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE (a:Laureate{Name: \"Andrea M. Ghez\"})RETURN a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea97fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE (a1:Laureate{Name:\" Andrea M. Ghez\"}),(a2:Laureate{Name:\"Ardem Patapoutia\"})RETURN a1,a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdf32b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cypher_gen(the_list):\n",
    "#     cypher_q = \"CREATE\"\n",
    "#     cypher_q1 = \"RETURN\"\n",
    "#     for i in range(0,len(the_list)):\n",
    "#         strr = str(the_list[i])\n",
    "        \n",
    "#         cypher_q += ' (d'+str(i)+':Date{date:'+\"\\\"\"+strr+\"\\\"\"+'}),'\n",
    "#         cypher_q1 += ' d'+str(i)+','\n",
    "#     print(cypher_q)\n",
    "#     print(cypher_q1)\n",
    "#     file = open('C:\\\\Users\\\\darby\\\\Desktop\\\\cypher_queries8.txt','w',encoding='utf8')\n",
    "#     file.write(cypher_q+cypher_q1)\n",
    "#     file.write(\"\\n\")\n",
    "#     file.close()\n",
    "\n",
    "# cypher_gen(npws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8eb01457",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dataframe.to_csv('C:\\\\Users\\\\darby\\\\Desktop\\\\dates_csv1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd964613",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = token_dataframe.to_numpy()\n",
    "\n",
    "is_born_on = list(dates[:,1])\n",
    "is_dead_on = list(dates[:,2])\n",
    "all_dates = is_born_on+is_dead_on\n",
    "# print(len(all_dates))\n",
    "all_the_dates = list(set(all_dates))\n",
    "# print(len(all_the_dates))\n",
    "# print(all_dates.count('NA'))\n",
    "\n",
    "# cypher_gen(all_the_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677fedfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATCH  (a:Genius { Name: \"Lionel Messi\" }), \n",
    "       (b:Genius { Name: \"Johnny Victory\"}), \n",
    "       (c:dob{date:'25 NOV 1996'}),\n",
    "       (d:dob{date:'25 NOVE 1996'}),\n",
    "       (e:dob{date:'25 JUNE 1996'})\n",
    "CREATE (a)-[R1:BORN_IN]->(c),\n",
    "       (a)-[R2:BORN_IN]->(d),\n",
    "       (b)-[R3:BORN_IN]->(e);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52a95b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cypher_gen(the_list):\n",
    "    cypher_q = \"MATCH\"\n",
    "    cypher_q1 = \"CREATE\"\n",
    "    for i in range(0,len(the_list)):\n",
    "        strr = str(the_list[i])\n",
    "        \n",
    "        if i<979:\n",
    "            cypher_q += ' (d'+str(i)+':Laureate{Name:'+\"\\\"\"+strr+\"\\\"\"+'}),'\n",
    "        else:\n",
    "            cypher_q += ' (d'+str(i)+':Date{date:'+\"\\\"\"+strr+\"\\\"\"+'}),'\n",
    "        cypher_q1 += ' (d'+str(i)+')-[R'+str(i)+':BORN_ON]->(d'+str(979+i)+')'+','\n",
    "#     print(cypher_q)\n",
    "#     print(cypher_q1)\n",
    "    file = open('C:\\\\Users\\\\darby\\\\Desktop\\\\cypher_queries_dates1.txt','w',encoding='utf8')\n",
    "    file.write(cypher_q+cypher_q1)\n",
    "    file.write(\"\\n\")\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b1f1063",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dates = token_dataframe.to_numpy()\n",
    "\n",
    "names = list(dates[:,0])\n",
    "is_born_on = list(dates[:,1])\n",
    "\n",
    "for_dates_of_birth = names+is_born\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6b13e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (d9)-[R9:BORN_ON]->(d987),\n",
      "(d9:Laureate{Name:\"jj\"}),\n"
     ]
    }
   ],
   "source": [
    "i = 9\n",
    "strr = 'jj'\n",
    "print(' (d'+str(i)+')-[R'+str(i)+':BORN_ON]->(d'+str(978+i)+')'+',')\n",
    "print('(d'+str(i)+':Laureate{Name:'+\"\\\"\"+strr+\"\\\"\"+'}),')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "045536e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_gen(for_dates_of_birth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "caa9e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = token_dataframe.to_numpy()\n",
    "\n",
    "names = list(dates[:,0])\n",
    "is_born_on = list(dates[:,2])\n",
    "\n",
    "for_dates_of_death = names+is_dead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7eb3cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cypher_gen(the_list):\n",
    "    cypher_q = \"MATCH\"\n",
    "    cypher_q1 = \"CREATE\"\n",
    "    for i in range(0,len(the_list)):\n",
    "        strr = str(the_list[i])\n",
    "        \n",
    "        if i<979:\n",
    "            cypher_q += ' (d'+str(i)+':Laureate{Name:'+\"\\\"\"+strr+\"\\\"\"+'}),'\n",
    "        else:\n",
    "            cypher_q += ' (d'+str(i)+':Date{date:'+\"\\\"\"+strr+\"\\\"\"+'}),'\n",
    "        if i<979:\n",
    "            cypher_q1 += ' (d'+str(i)+')-[R'+str(i)+':DEAD_ON]->(d'+str(979+i)+')'+','\n",
    "#     print(cypher_q)\n",
    "#     print(cypher_q1)\n",
    "        if i == 244 or i == 490 or i == 734 or i == 978:\n",
    "            file = open('C:\\\\Users\\\\darby\\\\Desktop\\\\cypher_for_death\\\\cypher_queries_ddates'+str(i)+'.txt','w',encoding='utf8')\n",
    "            file.write(cypher_q+cypher_q1)\n",
    "            file.write(\"\\n\")\n",
    "            file.close()\n",
    "            cypher_q = \"MATCH\"\n",
    "            cypher_q1 = \"CREATE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1e8f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_gen(for_dates_of_death)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b6a25877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cypher_gen(the_list):\n",
    "    cypher_q = \"MATCH\"\n",
    "    cypher_q1 = \"CREATE\"\n",
    "    for i in range(0,int(len(the_list)/2)):\n",
    "        strr = str(the_list[i])\n",
    "        strr1 = str(the_list[i+979])\n",
    "        \n",
    "        cypher_q += ' (d'+str(i)+':Laureate{Name:'+\"\\\"\"+strr+\"\\\"\"+'}),'\n",
    "        if(i%100 == 0 or i == 978):\n",
    "            cypher_q += ' (d'+str(979+i)+':Date{date:'+\"\\\"\"+strr1+\"\\\"\"+'})'\n",
    "        else:\n",
    "            cypher_q += ' (d'+str(979+i)+':Date{date:'+\"\\\"\"+strr1+\"\\\"\"+'}),'\n",
    "        if(i%100 == 0 or i == 978):\n",
    "            cypher_q1 += ' (d'+str(i)+')-[R'+str(i)+':DEAD_ON]->(d'+str(979+i)+')'\n",
    "        else:   \n",
    "            cypher_q1 += ' (d'+str(i)+')-[R'+str(i)+':DEAD_ON]->(d'+str(979+i)+')'+','\n",
    "#     print(cypher_q)\n",
    "#     print(cypher_q1)\n",
    "        if i%100 == 0 or i == 978 :\n",
    "            file = open('C:\\\\Users\\\\darby\\\\Desktop\\\\cypher_for_death\\\\cypher_queries_ddates'+str(i)+'.txt','w',encoding='utf8')\n",
    "            file.write(cypher_q+cypher_q1)\n",
    "            file.write(\"\\n\")\n",
    "            file.close()\n",
    "            cypher_q = \"MATCH\"\n",
    "            cypher_q1 = \"CREATE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b02ac241",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_gen(for_dates_of_death)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d86acb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy as sp\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "24e27de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Andrea Mia Ghez (born June 16, 1965) is an American astrophysicist and professor in the Department of Physics and Astronomy at the University of California, Los Angeles."
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8437821d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-92-f22b453a7cf3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-92-f22b453a7cf3>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    def nationality_extract:\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def nationality_extract:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "20600187",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andrea Mia Ghez PERSON\n",
      "June 16, 1965 DATE\n",
      "American NORP\n",
      "the Department of Physics ORG\n",
      "the University of California, Los Angeles ORG\n",
      "Patapoutian NORP\n",
      "Armenian NORP\n",
      "\\xd5\\x93\\xd5\\xa1\\xd5\\xa9\\xd5\\xa1\\xd6\\x83\\xd5\\xb8\\xd6\\x82\\xd5\\xa9\\xd5\\xa5\\xd5\\xa1\\xd5\\xb6 DATE\n",
      "2 October 1967 DATE\n",
      "American NORP\n",
      "Nobel Prize WORK_OF_ART\n",
      "Charles Moen Rice PERSON\n",
      "August 25, 1952 DATE\n",
      "American NORP\n",
      "Nobel Prize WORK_OF_ART\n",
      "David William PERSON\n",
      "16 March 1968 DATE\n",
      "Scottish NORP\n",
      "the James S. McDonnell Distinguished University ORG\n",
      "Princeton University ORG\n",
      "the Department of Chemistry ORG\n",
      "2010 to 2015 DATE\n",
      "Patrick Queloz PERSON\n",
      "French NORP\n",
      "kelo PERSON\n",
      "23 February 1966 DATE\n",
      "Swiss NORP\n",
      "Andreyevich Muratov PERSON\n",
      "Russian NORP\n",
      "30 October 1961 DATE\n",
      "Russian NORP\n",
      "Russian NORP\n",
      "Novaya Gazeta PERSON\n",
      "Giorgio Parisi PERSON\n",
      "4 August 1948 DATE\n",
      "Italian NORP\n",
      "quantum field ORG\n",
      "Klaus Ferdinand Hasselmann PERSON\n",
      "25 October 1931 DATE\n",
      "German NORP\n",
      "Malala Yousafzai PERSON\n",
      "\\xd9\\x85\\xd9\\x84\\xd8\\xa7\\xd9\\x84\\xd9\\x87 CARDINAL\n",
      "m\\xc9\\x99\\xcb\\x88la\\xcb\\x90l\\xc9\\x99 ORG\n",
      "12 July 1997 DATE\n",
      "Malala PERSON\n",
      "Pakistani NORP\n",
      "a Nobel Peace Prize WORK_OF_ART\n",
      "Michael Houghton PERSON\n",
      "1949 DATE\n",
      "British NORP\n",
      "Nobel Prize WORK_OF_ART\n"
     ]
    }
   ],
   "source": [
    "q = nlp('Andrea Mia Ghez (born June 16, 1965) is an American astrophysicist and professor in the Department of Physics and Astronomy at the University of California, Los Angeles')\n",
    "\n",
    "\n",
    "for k in range(0,10):\n",
    "    for i in sentences_list[k][0].ents:\n",
    "        \n",
    "            print(i.text,i.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db951241",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('is a ' in sentences_list[k][0] or 'is an ' in sentences_list[k][0]):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "65844214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Americanastrophysicist', 'American', 'Britishscientist', 'British', 'Americanbiochemist', 'American', 'Japanesephysician', 'Japanese', 'Americanastrophysicist', 'American', 'Soviet,', 'Soviet', 'Frenchsurgeon', 'French', 'Egyptianpolitician', 'Egyptian', 'Americanbiochemist', 'American', 'Finnishchemist', 'Finnish', 'Swedishneuropharmacologist', 'Swedish', 'Israelibiochemist', 'Israeli']\n"
     ]
    }
   ],
   "source": [
    "sl = sentences_list\n",
    "nationalities = []\n",
    "for k in range(0,100):\n",
    "#     print(k)\n",
    "#     print(entries[k])\n",
    "    \n",
    "    if len(sl[k])!=0:\n",
    "        for i in range(0,len(sl[k][0])):\n",
    "            if (str(sl[k][0][i]) == 'is' or str(sl[k][0][i]) == 'was'):\n",
    "                if(str(sl[k][0][i+1] )== 'a' or str(sl[k][0][i+1] )== 'an'):\n",
    "                    if(nlp(str(sl[k][0][i+2])).ents != () and nlp(str(sl[k][0][i+2])+str(sl[k][0][i+3])).ents != ()):\n",
    "                        if(nlp(str(sl[k][0][i+2])+str(sl[k][0][i+3])).ents[0].label_ == 'NORP'):\n",
    "                            nationalities.append(str(sl[k][0][i+2])+str(sl[k][0][i+3]))\n",
    "                            if(nlp(str(sl[k][0][i+2])).ents[0].label_ == 'NORP'):\n",
    "                                nationalities.append(str(sl[k][0][i+2]))\n",
    "                        \n",
    "print(nationalities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1eeaa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "print(len(nationalities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d85dd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      " Andrea M. Ghez.txt\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "American\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "[E1002] Span index out of range.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-7ed5257b96d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'is'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'was'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m \u001b[1;34m'an'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'NORP'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\tokens\\span.pyx\u001b[0m in \u001b[0;36mspacy.tokens.span.Span.__getitem__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: [E1002] Span index out of range."
     ]
    }
   ],
   "source": [
    "sl = sentences_list\n",
    "nationalities = []\n",
    "for k in range(0,100):\n",
    "    print(k)\n",
    "    print(entries[k])\n",
    "    \n",
    "    if len(sl[k])!=0:\n",
    "        for i in range(0,len(nlp((str(sl[k][0])+str(sl[k][1]))))):\n",
    "            \n",
    "            if (str(sl[k][0][i]) == 'is' or str(sl[k][0][i]) == 'was'):\n",
    "                if(str(sl[k][0][i+1] )== 'a' or str(sl[k][0][i+1] )== 'an'):\n",
    "                    if (nlp(str(sl[k][0][i+2])).ents[0].label_ == 'NORP'):\n",
    "                        print(str(sl[k][0][i+2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc3a9e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Andrea"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp((str(sl[0][0])+str(sl[0][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6bec209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NORP'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(str('Indian')).ents[0].label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b7549d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl[k][0][31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bcbed816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp((str(sl[k][0])+str(sl[k][1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "20c428dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "South African"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q233 = 'Allan MacLeod Cormack (February 23, 1924 \\xe2\\x80\\x93 May 7, 1998) was a South African American physicist who won the 1979 Nobel Prize in Physiology or Medicine (along with Godfrey Hounsfield) for his work on X-ray computed tomography (CT).'\n",
    "\n",
    "nlp(q233).ents\n",
    "\n",
    "q234 = 'South African American'\n",
    "nlp(q234).ents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "0a362609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['American', 'American', 'American', 'Scottish', 'Swiss', 'Russian', 'Italian', 'German', 'Pakistani', 'British', 'Swiss', 'Iraqi', 'American', 'American', 'German', 'Japanese', 'Japanese', 'Danish', 'Israeli', 'Tanzanian', 'Israeli', 'American', 'German', 'German', 'German', 'Argentine', 'Egyptian', 'Japanese', 'Japanese', 'American', 'American', 'Belgian', 'German', 'French', 'Alsatian', 'Hungarian', 'German', 'Russian', 'Scottish', 'Australian', 'Soviet', 'French', 'Mexican', 'American', 'Austrian', 'American', 'French', 'Swiss', 'Swedish', 'Swedish', 'American', 'Indian', 'French', 'Soviet', 'American', 'American', 'French', 'French', 'French', 'British', 'British', 'Portuguese', 'Egyptian', 'British', 'British', 'Israeli', 'Swedish', 'American', 'Canadian', 'American', 'British', 'British', 'American', 'American', 'Finnish', 'Swedish', 'Danish', 'British', 'Israeli', 'Turkish', 'American', 'American', 'American', 'Australian', 'American', 'Dutch', 'American', 'Swedish', 'Finnish', 'German', 'German', 'Argentine', 'German', 'Austrian', 'Swedish', 'Canadian', 'British', 'Norwegian', 'Russian', 'British', 'American', 'American', 'British', 'Indian', 'Italian', 'German', 'American', 'Czech', 'Swiss', 'German', 'American', 'Italian', 'Argentine', 'American', 'Swiss', 'Canadian', 'American', 'British', 'American', 'American', 'Chinese', 'French', 'French', 'French', 'Scottish', 'Swiss', 'Chinese', 'Dutch', 'American', 'Norwegian', 'German', 'American', 'French', 'French', 'American', 'British', 'American', 'Belgian', 'American', 'British', 'Argentine', 'Swedish', 'American', 'Swiss', 'Chinese', 'American', 'Israeli', 'American', 'American', 'Italian', 'American', 'Canadian', 'American', 'Canadian', 'British', 'American', 'American', 'American', 'British', 'Congolese', 'Hungarian', 'American', 'Belgian', 'American', 'American', 'Canadian', 'American', 'American', 'American', 'British', 'American', 'American', 'American', 'American', 'German', 'Norwegian', 'American', 'American', 'American', 'American', 'American', 'American', 'American', 'American', 'Japanese', 'Japanese', 'Austrian', 'German', 'American', 'Romanian', 'American', 'American', 'Australian', 'Liberian', 'German', 'Swiss', 'Italian', 'American', 'French', 'Italian', 'American', 'American', 'American', 'American', 'Swedish', 'American', 'Irish', 'Italian', 'German', 'German', 'German', 'German', 'French\\\\xe2\\\\x80\\\\x93American', 'American', 'American', 'Hungarian', 'Italian', 'Swedish', 'Swiss', 'German', 'French', 'American', 'Norwegian', 'American', 'American', 'Italian', 'American', 'Australian', 'American', 'American', 'Belgian', 'French', 'French', 'French', 'British', 'American', 'American', 'Danish', 'Norwegian', 'German', 'Austrian', 'Dutch', 'German', 'German', 'Slovenian', 'French', 'French', 'French', 'Colombian', 'Chilean', 'American', 'Hungarian', 'German', 'American', 'Hungarian', 'Irish', 'American', 'American', 'Romanian', 'American', 'American', 'American', 'British', 'British', 'American', 'American', 'American', 'American', 'Polish', 'German', 'American', 'Dutch', 'German', 'German', 'German', 'German', 'Italian', 'Greek', 'Italian', 'American', 'Italian', 'Pediatrician', 'Italian', 'Dutch', 'Swedish', 'Swedish', 'German', 'German', 'French', 'French', 'American', 'American', 'American', 'Swedish', 'German', 'German', 'German', 'German', 'German', 'German', 'Indian', 'German', 'American', 'British', 'American', 'American', 'Swedish', 'German', 'American', 'Dutch', 'German', 'German', 'Swiss', 'Dutch', 'French', 'French', 'Belgian', 'French', 'Danish', 'Danish', 'Swiss', 'Canadian', 'American', 'Polish', 'American', 'American', 'American', 'German', 'American', 'German', 'German', 'American', 'German', 'Japanese', 'Japanese', 'Japanese', 'Swedish', 'German', 'Australian', 'American', 'American', 'Swedish', 'Soviet', 'Soviet', 'American', 'French', 'Polish', 'Japanese', 'American', 'Russian', 'Norwegian', 'Yugoslav', 'German', 'British', 'American', 'American', 'German', 'Canadian', 'Dutch', 'French', 'American', 'British', 'American', 'American', 'American', 'German', 'American', 'British', 'British', 'American', 'American', 'American', 'Scottish', 'Dutch', 'Czech', 'French', 'French', 'French', 'French', 'French', 'French', 'American', 'American', 'Danish', 'American', 'American', 'German', 'American', 'German', 'Dutch', 'Danish', 'German', 'German', 'Danish', 'American', 'British', 'American', 'American', 'British', 'British', 'Australian', 'American', 'American', 'American', 'Hungarian', 'American', 'British', 'American', 'British', 'American', 'British', 'American', 'British', 'American', 'American', 'British', 'British', 'American', 'American', 'American', 'American', 'Polish', 'American', 'Israeli', 'American', 'Spanish', 'Portuguese', 'Colombian', 'Belgian', 'American', 'Austrian', 'Swedish', 'Indian', 'Danish', 'Swiss', 'American', 'German', 'German', 'German', 'British', 'Japanese', 'American', 'American', 'Japanese', 'American', 'Swedish', 'German', 'German', 'Norwegian', 'Ghanaian', 'Japanese', 'German', 'Austrian', 'Russian', 'German', 'Swiss', 'Norwegian', 'American', 'American', 'Vietnamese', 'Japanese', 'American', 'American', 'Polish', 'Soviet', 'Croatian', 'Canadian', 'Soviet', 'Liberian', 'American', 'American', 'American', 'British', 'French', 'American', 'French', 'American', 'French', 'German', 'Italian', 'Argentine', 'American', 'French', 'French', 'British', 'Pakistani', 'German', 'Swedish', 'German', 'Polish', 'Italian', 'Mexican', 'American', 'American', 'British', 'Austrian', 'American', 'American', 'American', 'Dutch', 'Finnish', 'Japanese', 'French', 'Belgian', 'German', 'Austrian', 'German', 'German', 'Norwegian', 'American', 'American', 'American', 'British', 'American', 'American', 'American', 'American', 'Swiss', 'Russian', 'Russian', 'American', 'Egyptian', 'American', 'Canadian', 'Iraqi', 'German', 'British', 'American', 'Dutch', 'Danish', 'Danish', 'Danish', 'Dutch', 'Soviet', 'Soviet', 'American', 'American', 'British', 'Mexican', 'Norwegian', 'Greek', 'Polish', 'British', 'British', 'Turkish', 'Japanese', 'German', 'German', 'German', 'German', 'German', 'German', 'German', 'American', 'British', 'Chilean', 'British', 'French', 'Australian', 'American', 'American', 'American', 'American', 'Swiss', 'Dutch', 'Swiss', 'American', 'American', 'American', 'American', 'American', 'American', 'French', 'Soviet', 'American', 'American', 'American', 'American', 'Australian', 'British', 'Dutch', 'German', 'Austrian', 'British', 'Brazilian', 'British', 'British', 'American', 'American', 'Hungarian', 'French', 'French', 'Dutch', 'German', 'Swedish', 'Indian', 'Finnish', 'American', 'American', 'Canadian', 'American', 'American', 'German', 'German', 'French', 'Italian', 'American', 'Canadian', 'American', 'American', 'British', 'Austrian', 'British', 'Swiss', 'American', 'German', 'Italian', 'American', 'Israeli', 'American', 'American', 'American', 'American', 'American', 'American', 'American', 'British', 'American', 'American', 'German', 'German', 'American', 'Canadian', 'American', 'American', 'American', 'American', 'Australian', 'American', 'British', 'American', 'French', 'French', 'American', 'American', 'American', 'French', 'British', 'British', 'American', 'American', 'German', 'German', 'Canadian', 'American', 'Japanese', 'French', 'Italian', 'Italian', 'Irish', 'Chinese', 'Spanish', 'Japanese', 'Irish', 'Swedish', 'Russian', 'French', 'Spanish', 'Irish', 'Israeli', 'Iranian', 'Japanese', 'Canadian', 'Norwegian', 'American', 'Dutch', 'Japanese', 'American', 'American', 'American', 'Romanian', 'American', 'Indian', 'French', 'Japanese', 'Swedish', 'Belarusian', 'Polish', 'Japanese', 'Yemeni', 'Scottish', 'British', 'German', 'Swedish', 'German', 'American', 'American', 'American', 'German', 'American', 'American', 'American', 'American', 'British', 'Dutch', 'Dutch', 'Swedish', 'Swedish', 'Swedish', 'Japanese', 'Chinese', 'Swedish', 'American', 'Indian', 'Swedish', 'American', 'Spanish', 'Austrian', 'French', 'American', 'Russian', 'Croatian', 'Irish', 'American', 'American', 'Austrian', 'Swiss', 'German', 'German', 'Kenyan', 'American', 'German', 'Baltic', 'German', 'American', 'Canadian', 'Dutch', 'American', 'Irish', 'American', 'American', 'British', 'American', 'American', 'Australian', 'American', 'American', 'American', 'American', 'Canadian', 'American', 'British', 'Polish', 'Nigerian', 'German', 'German', 'American', 'Polish', 'Japanese', 'Israeli', 'Japanese', 'Japanese', 'Taiwanese', 'French', 'Soviet', 'Swiss', 'Russian']\n",
      "767\n",
      "[19, 21, 22, 23, 33, 35, 36, 38, 42, 57, 58, 63, 64, 66, 69, 74, 82, 85, 92, 96, 97, 106, 119, 121, 125, 126, 131, 139, 152, 158, 161, 165, 172, 176, 195, 196, 197, 203, 204, 211, 222, 244, 248, 249, 256, 262, 264, 271, 273, 279, 285, 287, 289, 290, 295, 304, 306, 308, 315, 321, 325, 333, 338, 339, 342, 345, 346, 348, 358, 359, 362, 376, 393, 394, 407, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 431, 436, 442, 443, 445, 450, 458, 463, 468, 469, 482, 494, 497, 503, 508, 510, 513, 515, 521, 531, 534, 535, 537, 546, 549, 555, 572, 573, 574, 586, 591, 602, 603, 608, 609, 613, 621, 627, 629, 632, 637, 641, 643, 644, 648, 652, 654, 655, 658, 660, 661, 662, 663, 665, 675, 676, 684, 687, 705, 706, 710, 716, 719, 733, 740, 745, 746, 749, 754, 759, 762, 767, 773, 774, 775, 777, 779, 782, 786, 789, 791, 797, 798, 802, 814, 817, 819, 827, 837, 838, 845, 848, 856, 861, 864, 868, 869, 870, 874, 882, 885, 889, 896, 899, 901, 902, 904, 905, 906, 907, 908, 927, 929, 930, 933, 941, 943, 945, 949, 953, 954, 958, 964, 966, 968, 978]\n"
     ]
    }
   ],
   "source": [
    "sl = sentences_list\n",
    "nationalities = []\n",
    "no = []\n",
    "for k in range(0,979):\n",
    "#     print(k)\n",
    "#     print(entries[k])\n",
    "    \n",
    "    if len(sl[k])!=0:\n",
    "        for i in range(0,len(sl[k][0])):\n",
    "            if (str(sl[k][0][i]) == 'is' or str(sl[k][0][i]) == 'was'):\n",
    "                if(i+1<len(sl[k][0])):\n",
    "                    if(str(sl[k][0][i+1] )== 'a' or str(sl[k][0][i+1] )== 'an'):\n",
    "                        if(nlp(str(sl[k][0][i+2])).ents != ()):\n",
    "                            if(nlp(str(sl[k][0][i+2])).ents[0].label_ == 'NORP'):\n",
    "                                no.append(k)\n",
    "                                nationalities.append(str(sl[k][0][i+2]))\n",
    "\n",
    "\n",
    "numbers_not_present = list(filter(lambda x: x not in no,range(0,979)))\n",
    "print(nationalities)\n",
    "\n",
    "print(len(nationalities))\n",
    "print(numbers_not_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf6fc227",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2eaaea6e69bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mex_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m21\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m22\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m23\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m33\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m35\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m36\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m38\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m57\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m58\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m63\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m66\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m69\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m74\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m82\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m85\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m92\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m96\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m97\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m106\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m119\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m121\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m125\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m126\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m131\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m139\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m152\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m158\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m161\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m165\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m172\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m176\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m195\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m196\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m197\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m203\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m204\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m211\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m222\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m244\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m248\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m249\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m262\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m264\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m271\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m273\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m279\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m285\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m287\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m289\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m290\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m295\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m304\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m306\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m308\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m315\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m321\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m325\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m333\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m338\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m339\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m342\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m345\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m346\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m348\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m358\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m359\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m362\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m376\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m393\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m394\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m407\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m419\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m420\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m421\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m422\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m423\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m424\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m425\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m426\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m427\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m428\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m429\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m431\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m436\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m442\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m443\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m445\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m450\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m458\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m463\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m468\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m469\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m482\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m494\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m497\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m503\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m508\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m510\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m513\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m515\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m521\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m531\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m534\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m535\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m537\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m546\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m549\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m555\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m572\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m573\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m574\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m586\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m591\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m602\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m603\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m608\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m609\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m613\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m621\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m627\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m629\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m632\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m637\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m641\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m643\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m644\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m648\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m652\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m654\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m655\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m658\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m660\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m661\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m662\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m663\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m665\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m675\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m676\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m684\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m687\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m705\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m706\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m710\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m716\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m719\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m733\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m740\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m745\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m746\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m749\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m754\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m759\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m762\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m767\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m773\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m774\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m775\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m777\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m779\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m782\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m786\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m789\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m791\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m797\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m798\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m802\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m814\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m817\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m819\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m827\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m837\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m838\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m845\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m848\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m856\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m861\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m864\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m868\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m869\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m870\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m874\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m882\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m885\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m889\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m896\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m899\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m901\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m902\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m904\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m905\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m906\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m907\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m908\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m927\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m929\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m930\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m933\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m941\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m943\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m945\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m949\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m953\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m954\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m958\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m964\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m966\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m968\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m978\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "ex_ = [19, 21, 22, 23, 33, 35, 36, 38, 42, 57, 58, 63, 64, 66, 69, 74, 82, 85, 92, 96, 97, 106, 119, 121, 125, 126, 131, 139, 152, 158, 161, 165, 172, 176, 195, 196, 197, 203, 204, 211, 222, 244, 248, 249, 256, 262, 264, 271, 273, 279, 285, 287, 289, 290, 295, 304, 306, 308, 315, 321, 325, 333, 338, 339, 342, 345, 346, 348, 358, 359, 362, 376, 393, 394, 407, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 431, 436, 442, 443, 445, 450, 458, 463, 468, 469, 482, 494, 497, 503, 508, 510, 513, 515, 521, 531, 534, 535, 537, 546, 549, 555, 572, 573, 574, 586, 591, 602, 603, 608, 609, 613, 621, 627, 629, 632, 637, 641, 643, 644, 648, 652, 654, 655, 658, 660, 661, 662, 663, 665, 675, 676, 684, 687, 705, 706, 710, 716, 719, 733, 740, 745, 746, 749, 754, 759, 762, 767, 773, 774, 775, 777, 779, 782, 786, 789, 791, 797, 798, 802, 814, 817, 819, 827, 837, 838, 845, 848, 856, 861, 864, 868, 869, 870, 874, 882, 885, 889, 896, 899, 901, 902, 904, 905, 906, 907, 908, 927, 929, 930, 933, 941, 943, 945, 949, 953, 954, 958, 964, 966, 968, 978]\n",
    "\n",
    "text[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "451a32a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rigoberta Mench\\xc3\\xba"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl[777][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0d6190ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NORP'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl[161][0].ents[2].label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a79ca4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Desmond Mpilo Tutu  (born 7 October 1931) is a South African Anglican cleric and theologian, known for his work as an anti-apartheid and human rights activist."
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl[197][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af1302b",
   "metadata": {},
   "source": [
    "Lithuanian-born British biophysicist and  chemist\n",
    "India-born naturalized American\n",
    "New Zealand-born American chemist\n",
    "was a Nobel Prize-winning Belgian cytologist and biochemist\n",
    "was a Nobel Prize-winning American physicist\n",
    "English physiologist and biophysicist\n",
    "was an English physiologist and biophysicist\n",
    "was the Prime Minister of Belgium\n",
    "was a peace activist from Northern Ireland\n",
    "was an English neurophysiologist\n",
    "\n",
    "South African American\n",
    "Venezuelan-American immunologist\n",
    "\n",
    "is an East Timorese Roman Catholic bishop.\n",
    "was a Saint Lucian poet and playwright\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "28bbb3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Venezuelan American\n"
     ]
    }
   ],
   "source": [
    "q1 = nlp('Venezuelan-American immunologist')\n",
    "\n",
    "def migrant(q1):\n",
    "    for i in range(0,len(q1)):\n",
    "        if(str(q1[i]) == '-'):\n",
    "            if(nlp(str(q1[i-1])).ents[0].label_ == 'NORP' and nlp(str(q1[i+1])).ents[0].label_ == 'NORP'):\n",
    "                return (q1[i-1]+\" \"+q1[i+1])\n",
    "            if(str(q1[i+1]) == 'born'):\n",
    "                for j in q1[i+2:]:\n",
    "                    if nlp(str(j)).ents != ():\n",
    "                        if nlp(str(j)).ents[0].label_ == 'NORP':\n",
    "                            return(q1[i-1]+\" \"+q1[i+1]+\" \"+j)\n",
    "                            break\n",
    "                if nlp(str(q1[i+2])).ents != ():\n",
    "                    if(nlp(str(q1[i+2])).ents[0].label_ == 'NORP'):\n",
    "                        return(q1[i-1]+\" \"+q1[i+1]+\" \"+q1[i+2])\n",
    "    \n",
    "\n",
    "migrant(q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "e87a605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exceptional_nationalities(q1):\n",
    "    nat = ['SOUTH AFRICAN',\n",
    " 'COSTA RICAN',\n",
    " 'SAINT LUCIAN',\n",
    " 'NEW ZEALANDER',\n",
    " 'NORTH KOREAN',\n",
    " 'SAUDI ARABIAN',\n",
    " 'SIERRA LEONIAN',\n",
    " 'SOLOMON ISLANDER',\n",
    " 'SOUTH KOREAN',\n",
    " 'SRI LANKAN',\n",
    " 'WESTERN SAMOAN',\n",
    "'EAST TIMORESE']\n",
    "    \n",
    "    for i in range(0,len(q1)):\n",
    "        if i+1<len(q1):\n",
    "#             print(q1[i])\n",
    "            if(str(q1[i]).upper()+\" \"+str(q1[i+1]).upper() in nat):\n",
    "#                 print(1)\n",
    "            \n",
    "                if(i+2>=len(q1)):\n",
    "                    return str(q1[i]).upper()+\" \"+str(q1[i+1]).upper()\n",
    "            \n",
    "                if(nlp(str(q1[i+2])).ents[0].label_ == 'NORP'):\n",
    "                    return str(q1[i]).upper()+\" \"+str(q1[i+1]).upper()+\" \"+str(q1[i+2]).upper()\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "b1102ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SOUTH AFRICAN',\n",
       " 'COSTA RICAN',\n",
       " 'SAINT LUCIAN',\n",
       " 'NEW ZEALANDER',\n",
       " 'NORTH KOREAN',\n",
       " 'SAUDI ARABIAN',\n",
       " 'SIERRA LEONIAN',\n",
       " 'SIERRA LEONIAN',\n",
       " 'SOLOMON ISLANDER',\n",
       " 'SOUTH KOREAN',\n",
       " 'SRI LANKAN',\n",
       " 'WESTERN SAMOAN']"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nat = ['South African','Costa Rican','Saint Lucian','New Zealander','North Korean'\n",
    "           ,'Saudi Arabian','Sierra Leonian', 'Sierra Leonian', 'Solomon Islander', \n",
    "           'South Korean', 'Sri Lankan', 'Western Samoan']\n",
    "\n",
    "nat_cap = [i.upper() for i in nat]\n",
    "nat_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "a7090769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAINT LUCIAN\n"
     ]
    }
   ],
   "source": [
    "print(exceptional_nationalities(nlp('You are a Saint Lucian')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "eca3395e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[New Zealand]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 'New Zealand is a great country'\n",
    "e = 'I am a South African American'\n",
    "f = 'You are a Saint Lucian'\n",
    "g = 'Moly is a Costa Rican'\n",
    "[i for i in nlp(w).ents]\n",
    "# [j for j in nlp(e)]\n",
    "# [k for k in nlp(f)]\n",
    "# [l for l in nlp(g)]\n",
    "# nlp(w).ents[0].label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "b6d03625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Charles Moen Rice (born August 25, 1952) is an American virologist and Nobel Prize laureate whose main area of research is the Hepatitis C virus.,\n",
       " He is a professor of virology at the Rockefeller University in New York City and an adjunct professor at Cornell University and Washington University School of Medicine.,\n",
       " At the time of the award he was a faculty at Rockefeller.,\n",
       "  \\nRice is a Fellow of the American Association for the Advancement of Science, member of the National Academy of Sciences and was president of the American Society for Virology from 2002 to 2003.,\n",
       " He received the 2016 Lasker-DeBakey Clinical Medical Research Award, jointly with Ralf F. W. Bartenschlager and Michael J. Sofia.,\n",
       " Along with Michael Houghton and Harvey J. Alter, he was awarded the 2020 Nobel Prize in Physiology or Medicine \"for the discovery of Hepatitis C virus.\"']"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
